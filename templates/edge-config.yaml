# Edge collector: receives OTLP from nodes, exports to NATS, Kafka, or downstream OTLP
{{- if .Values.edge.enabled }}
apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ include "otel-collector.edgeFullname" . }}
  labels:
    {{- include "otel-collector.labels" . | nindent 4 }}
    app.kubernetes.io/component: edge
data:
  config.yaml: |
    receivers:
      otlp:
        protocols:
          grpc:
            endpoint: 0.0.0.0:4317
          http:
            endpoint: 0.0.0.0:4318

    {{- if .Values.edge.persistentQueue.enabled }}
    extensions:
      file_storage:
        directory: {{ .Values.edge.persistentQueue.directory | quote }}
    {{- end }}

    processors:
      batch:
        timeout: 5s
        send_batch_size: 10000
      memory_limiter:
        check_interval: 1s
        limit_mib: 400
        spike_limit_mib: 128
      {{- if and (eq .Values.edge.queueBackend "kafka") .Values.edge.kafka.auditLogsOnly }}
      # Keep only logs with attribute type=audit (drop others)
      filter/audit:
        error_mode: ignore
        logs:
          log_record:
            - 'attributes["{{ .Values.edge.kafka.auditLogAttributeKey }}"] != "{{ .Values.edge.kafka.auditLogAttributeValue }}"'
      # Keep only logs without type=audit (drop audit logs)
      filter/not_audit:
        error_mode: ignore
        logs:
          log_record:
            - 'attributes["{{ .Values.edge.kafka.auditLogAttributeKey }}"] == "{{ .Values.edge.kafka.auditLogAttributeValue }}"'
      {{- end }}

    exporters:
      {{- if and (eq .Values.edge.queueBackend "otlp") .Values.edge.otlpLoadBalancing }}
      # Trace-ID routing so all spans of a trace hit the same downstream replica (enables tail-based sampling with multiple replicas). Metrics/logs use otlphttp (traceID only supported for traces).
      loadbalancing:
        routing_key: traceID
        protocol:
          otlp:
            tls:
              insecure: true
        resolver:
          dns:
            hostname: {{ include "otel-collector.downstreamHeadlessHost" . | quote }}
            port: "4317"
            interval: {{ .Values.edge.otlpLoadBalancingResolver.interval | quote }}
            timeout: {{ .Values.edge.otlpLoadBalancingResolver.timeout | quote }}
      otlphttp:
        endpoint: {{ include "otel-collector.downstreamOtlpEndpoint" . | quote }}
        tls:
          insecure: true
        {{- if .Values.edge.persistentQueue.enabled }}
        sending_queue:
          enabled: true
          storage: file_storage
          num_consumers: 4
          queue_size: {{ .Values.edge.persistentQueue.queueSize }}
        {{- end }}
      {{- else if eq .Values.edge.queueBackend "nats" }}
      # NATS exporter (proposed in contrib; use custom collector image if not yet available)
      nats:
        server_url: {{ .Values.edge.nats.url | quote }}
        traces:
          subject: {{ .Values.edge.nats.traces.subject | quote }}
          encoding: {{ .Values.edge.nats.traces.encoding | quote }}
        metrics:
          subject: {{ .Values.edge.nats.metrics.subject | quote }}
          encoding: {{ .Values.edge.nats.metrics.encoding | quote }}
        logs:
          subject: {{ .Values.edge.nats.logs.subject | quote }}
          encoding: {{ .Values.edge.nats.logs.encoding | quote }}
        {{- if .Values.edge.persistentQueue.enabled }}
        sending_queue:
          enabled: true
          storage: file_storage
          num_consumers: 4
          queue_size: {{ .Values.edge.persistentQueue.queueSize }}
        {{- end }}
      {{- else if eq .Values.edge.queueBackend "kafka" }}
      {{- if .Values.edge.kafka.auditLogsOnly }}
      # Audit-logs-only: traces/metrics/other logs go to downstream via OTLP; only audit logs go to Kafka
      otlphttp:
        endpoint: {{ include "otel-collector.downstreamOtlpEndpoint" . | quote }}
        tls:
          insecure: true
        {{- if .Values.edge.persistentQueue.enabled }}
        sending_queue:
          enabled: true
          storage: file_storage
          num_consumers: 4
          queue_size: {{ .Values.edge.persistentQueue.queueSize }}
        {{- end }}
      kafka/logs:
        protocol_version: {{ .Values.edge.kafka.protocolVersion | quote }}
        brokers: {{ toJson .Values.edge.kafka.brokers }}
        topic: {{ .Values.edge.kafka.logs.topic | quote }}
        encoding: {{ .Values.edge.kafka.logs.encoding | quote }}
        {{- if .Values.edge.kafka.producer }}
        producer:
          required_acks: {{ .Values.edge.kafka.producer.requiredAcks }}
        {{- end }}
        {{- if .Values.edge.kafka.retryOnFailure.enabled }}
        retry_on_failure:
          enabled: true
          initial_interval: {{ .Values.edge.kafka.retryOnFailure.initialInterval | quote }}
          max_interval: {{ .Values.edge.kafka.retryOnFailure.maxInterval | quote }}
          max_elapsed_time: {{ .Values.edge.kafka.retryOnFailure.maxElapsedTime | quote }}
        {{- end }}
        {{- if .Values.edge.persistentQueue.enabled }}
        sending_queue:
          enabled: true
          storage: file_storage
          num_consumers: 4
          queue_size: {{ .Values.edge.persistentQueue.queueSize }}
        {{- end }}
      {{- else }}
      kafka/traces:
        protocol_version: {{ .Values.edge.kafka.protocolVersion | quote }}
        brokers: {{ toJson .Values.edge.kafka.brokers }}
        topic: {{ .Values.edge.kafka.traces.topic | quote }}
        encoding: {{ .Values.edge.kafka.traces.encoding | quote }}
        partition_traces_by_id: {{ .Values.edge.kafka.partitionTracesById }}
        {{- if .Values.edge.kafka.producer }}
        producer:
          required_acks: {{ .Values.edge.kafka.producer.requiredAcks }}
        {{- end }}
        {{- if .Values.edge.kafka.retryOnFailure.enabled }}
        retry_on_failure:
          enabled: true
          initial_interval: {{ .Values.edge.kafka.retryOnFailure.initialInterval | quote }}
          max_interval: {{ .Values.edge.kafka.retryOnFailure.maxInterval | quote }}
          max_elapsed_time: {{ .Values.edge.kafka.retryOnFailure.maxElapsedTime | quote }}
        {{- end }}
        {{- if .Values.edge.persistentQueue.enabled }}
        sending_queue:
          enabled: true
          storage: file_storage
          num_consumers: 4
          queue_size: {{ .Values.edge.persistentQueue.queueSize }}
        {{- end }}
      kafka/metrics:
        protocol_version: {{ .Values.edge.kafka.protocolVersion | quote }}
        brokers: {{ toJson .Values.edge.kafka.brokers }}
        topic: {{ .Values.edge.kafka.metrics.topic | quote }}
        encoding: {{ .Values.edge.kafka.metrics.encoding | quote }}
        {{- if .Values.edge.kafka.producer }}
        producer:
          required_acks: {{ .Values.edge.kafka.producer.requiredAcks }}
        {{- end }}
        {{- if .Values.edge.kafka.retryOnFailure.enabled }}
        retry_on_failure:
          enabled: true
          initial_interval: {{ .Values.edge.kafka.retryOnFailure.initialInterval | quote }}
          max_interval: {{ .Values.edge.kafka.retryOnFailure.maxInterval | quote }}
          max_elapsed_time: {{ .Values.edge.kafka.retryOnFailure.maxElapsedTime | quote }}
        {{- end }}
        {{- if .Values.edge.persistentQueue.enabled }}
        sending_queue:
          enabled: true
          storage: file_storage
          num_consumers: 4
          queue_size: {{ .Values.edge.persistentQueue.queueSize }}
        {{- end }}
      kafka/logs:
        protocol_version: {{ .Values.edge.kafka.protocolVersion | quote }}
        brokers: {{ toJson .Values.edge.kafka.brokers }}
        topic: {{ .Values.edge.kafka.logs.topic | quote }}
        encoding: {{ .Values.edge.kafka.logs.encoding | quote }}
        {{- if .Values.edge.kafka.producer }}
        producer:
          required_acks: {{ .Values.edge.kafka.producer.requiredAcks }}
        {{- end }}
        {{- if .Values.edge.kafka.retryOnFailure.enabled }}
        retry_on_failure:
          enabled: true
          initial_interval: {{ .Values.edge.kafka.retryOnFailure.initialInterval | quote }}
          max_interval: {{ .Values.edge.kafka.retryOnFailure.maxInterval | quote }}
          max_elapsed_time: {{ .Values.edge.kafka.retryOnFailure.maxElapsedTime | quote }}
        {{- end }}
        {{- if .Values.edge.persistentQueue.enabled }}
        sending_queue:
          enabled: true
          storage: file_storage
          num_consumers: 4
          queue_size: {{ .Values.edge.persistentQueue.queueSize }}
        {{- end }}
      {{- end }}
      {{- else }}
      otlphttp:
        endpoint: {{ include "otel-collector.downstreamOtlpEndpoint" . | quote }}
        tls:
          insecure: true
        {{- if .Values.edge.persistentQueue.enabled }}
        sending_queue:
          enabled: true
          storage: file_storage
          num_consumers: 4
          queue_size: {{ .Values.edge.persistentQueue.queueSize }}
        {{- end }}
      {{- end }}

    service:
      {{- if .Values.edge.persistentQueue.enabled }}
      extensions: [file_storage]
      {{- end }}
      pipelines:
        traces:
          receivers: [otlp]
          processors: [memory_limiter, batch]
          exporters: [{{ include "otel-collector.edgeTracesExporter" . }}]
        metrics:
          receivers: [otlp]
          processors: [memory_limiter, batch]
          exporters: [{{ include "otel-collector.edgeMetricsExporter" . }}]
        {{- if and (eq .Values.edge.queueBackend "kafka") .Values.edge.kafka.auditLogsOnly }}
        logs/audit:
          receivers: [otlp]
          processors: [memory_limiter, filter/audit, batch]
          exporters: [kafka/logs]
        logs/other:
          receivers: [otlp]
          processors: [memory_limiter, filter/not_audit, batch]
          exporters: [otlphttp]
        {{- else }}
        logs:
          receivers: [otlp]
          processors: [memory_limiter, batch]
          exporters: [{{ include "otel-collector.edgeLogsExporter" . }}]
        {{- end }}
      telemetry:
        logs:
          level: info
        metrics:
          address: 0.0.0.0:8888
{{- end }}
