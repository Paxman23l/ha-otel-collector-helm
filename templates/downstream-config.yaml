# Downstream collector: receives from OTLP (or NATS), exports to GCP and ClickHouse
{{- if .Values.downstream.enabled }}
apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ include "otel-collector.downstreamFullname" . }}
  labels:
    {{- include "otel-collector.labels" . | nindent 4 }}
    app.kubernetes.io/component: downstream
data:
  config.yaml: |
    receivers:
      otlp:
        protocols:
          grpc:
            endpoint: 0.0.0.0:4317
          http:
            endpoint: 0.0.0.0:4318
      {{- if .Values.downstream.useNatsReceiver }}
      # NATS receiver (when available in contrib)
      nats:
        server_url: {{ .Values.downstream.nats.url | quote }}
        traces:
          subject: {{ .Values.downstream.nats.tracesSubject | quote }}
        metrics:
          subject: {{ .Values.downstream.nats.metricsSubject | quote }}
        logs:
          subject: {{ .Values.downstream.nats.logsSubject | quote }}
      {{- end }}
      {{- if .Values.downstream.useKafkaReceiver }}
      # Kafka receivers (type "kafka" with named instances: kafka/traces, kafka/metrics, kafka/logs)
      kafka/traces:
        protocol_version: {{ .Values.downstream.kafka.protocolVersion | quote }}
        brokers: {{ toJson .Values.downstream.kafka.brokers }}
        topic: {{ .Values.downstream.kafka.traces.topic | quote }}
        encoding: {{ .Values.downstream.kafka.traces.encoding | quote }}
        group_id: {{ .Values.downstream.kafka.groupId | quote }}
      kafka/metrics:
        protocol_version: {{ .Values.downstream.kafka.protocolVersion | quote }}
        brokers: {{ toJson .Values.downstream.kafka.brokers }}
        topic: {{ .Values.downstream.kafka.metrics.topic | quote }}
        encoding: {{ .Values.downstream.kafka.metrics.encoding | quote }}
        group_id: {{ .Values.downstream.kafka.groupId | quote }}
      kafka/logs:
        protocol_version: {{ .Values.downstream.kafka.protocolVersion | quote }}
        brokers: {{ toJson .Values.downstream.kafka.brokers }}
        topic: {{ .Values.downstream.kafka.logs.topic | quote }}
        encoding: {{ .Values.downstream.kafka.logs.encoding | quote }}
        group_id: {{ .Values.downstream.kafka.groupId | quote }}
      {{- end }}

    {{- if .Values.downstream.persistentQueue.enabled }}
    extensions:
      file_storage:
        directory: {{ .Values.downstream.persistentQueue.directory | quote }}
    {{- end }}

    processors:
      batch:
        timeout: 10s
        send_batch_size: 10000
      memory_limiter:
        check_interval: 1s
        limit_mib: 1500
        spike_limit_mib: 512
      {{- if .Values.downstream.tailSampling.enabled }}
      tail_sampling:
        decision_wait: {{ .Values.downstream.tailSampling.decisionWait | quote }}
        num_traces: {{ .Values.downstream.tailSampling.numTraces }}
        expected_new_traces_per_sec: {{ .Values.downstream.tailSampling.expectedNewTracesPerSec }}
        policies:
          {{- range .Values.downstream.tailSampling.policies }}
          - name: {{ .name | quote }}
            type: {{ .type | quote }}
            {{- if eq .type "status_code" }}
            status_code:
              status_codes: {{ toJson .statusCode.statusCodes }}
            {{- else if eq .type "latency" }}
            latency:
              threshold_ms: {{ .latency.thresholdMs }}
            {{- else if eq .type "probabilistic" }}
            probabilistic:
              sampling_percentage: {{ .probabilistic.samplingPercentage }}
            {{- else if eq .type "always_sample" }}
            always_sample: {}
            {{- end }}
          {{- end }}
      {{- end }}

    exporters:
      {{- if .Values.downstream.debugExporter.enabled }}
      debug:
        verbosity: {{ .Values.downstream.debugExporter.verbosity | quote }}
      {{- end }}
      {{- if .Values.downstream.gcp.enabled }}
      googlecloud:
        project: {{ .Values.downstream.gcp.project | quote }}
        {{- if .Values.downstream.gcp.credentialsFile }}
        credentials_file: {{ .Values.downstream.gcp.credentialsFile | quote }}
        {{- end }}
        {{- if .Values.downstream.persistentQueue.enabled }}
        sending_queue:
          enabled: true
          storage: file_storage
          num_consumers: 4
          queue_size: {{ .Values.downstream.persistentQueue.queueSize }}
        {{- end }}
      {{- end }}
      {{- if .Values.downstream.clickhouse.enabled }}
      clickhouse:
        endpoint: {{ .Values.downstream.clickhouse.endpoint | quote }}
        database: {{ .Values.downstream.clickhouse.database | quote }}
        {{- if .Values.downstream.persistentQueue.enabled }}
        sending_queue:
          enabled: true
          storage: file_storage
          num_consumers: 4
          queue_size: {{ .Values.downstream.persistentQueue.queueSize }}
        {{- end }}
      {{- end }}

    service:
      {{- if .Values.downstream.persistentQueue.enabled }}
      extensions: [file_storage]
      {{- end }}
      pipelines:
        traces:
          receivers: [otlp{{ if .Values.downstream.useNatsReceiver }}, nats{{ end }}{{ if .Values.downstream.useKafkaReceiver }}, kafka/traces{{ end }}]
          processors: [memory_limiter, batch{{ if .Values.downstream.tailSampling.enabled }}, tail_sampling{{ end }}]
          exporters: [{{ include "otel-collector.downstreamExporters" . }}]
        metrics:
          receivers: [otlp{{ if .Values.downstream.useNatsReceiver }}, nats{{ end }}{{ if .Values.downstream.useKafkaReceiver }}, kafka/metrics{{ end }}]
          processors: [memory_limiter, batch]
          exporters: [{{ include "otel-collector.downstreamExporters" . }}]
        logs:
          receivers: [otlp{{ if .Values.downstream.useNatsReceiver }}, nats{{ end }}{{ if .Values.downstream.useKafkaReceiver }}, kafka/logs{{ end }}]
          processors: [memory_limiter, batch]
          exporters: [{{ include "otel-collector.downstreamExporters" . }}]
      telemetry:
        logs:
          level: info
        metrics:
          address: 0.0.0.0:8888
{{- end }}
